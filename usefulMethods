import numpy as np
import scipy.stats as ss
from scipy import interpolate
from scipy import integrate
from scipy.integrate import simpson, trapezoid, cumulative_trapezoid, fixed_quad
import scipy.stats as ss
from scipy.optimize import minimize

# Settings for all code experiments. setting paradigm
experimentRange = "00to180" #"45to225"
max_val = 42
min_val = 2

factor_val = max_val - min_val

if experimentRange == "00to45" or experimentRange == "45to90" or experimentRange == "00to90":
    end = int(experimentRange[-2:])
    start = int(experimentRange[0:2])
if experimentRange == "90to135" or experimentRange == "90to180":
    end = int(experimentRange[-3:])
    start = int(experimentRange[0:2])
if experimentRange == "135to180":
    end = int(experimentRange[-3:])
    start = int(experimentRange[0:3])
if experimentRange == "00to180":
    end = 180
    start = 0
if experimentRange == "45to225":
    end = 225
    start = 45

displace = start/90.*np.pi

stim_ori_grid = np.linspace(start, end, 501) * np.pi / 90
rep_ori_grid = np.linspace(start, end, 501) * np.pi / 90

# import riskSingleObserverPercept as model

# sensory noise with all possible folding, truncation effects etc. Not used anymore sinc e now we are using 
# a 180 degree range
def sensory_noise(m, sigma_rep, grid, type):
    truncBoth = ss.truncnorm.pdf(grid,(min_val - m) / sigma_rep, (max_val -m) / sigma_rep, m, sigma_rep)
    # truncUp = ss.truncnorm.pdf(grid, (-np.Inf - m) / sigma_rep, (1. - m) / sigma_rep, m, sigma_rep)
    # truncLow = ss.truncnorm.pdf(grid, (0.0 - m) / sigma_rep, (np.Inf - m) / sigma_rep, m, sigma_rep)
    # foldUp = ss.foldnorm.pdf(1-grid, (1-m)/sigma_rep, 0.0, sigma_rep) # 0.0 here is essentially the point of the folding
    # foldLow = ss.foldnorm.pdf(grid, m/sigma_rep, 0.0, sigma_rep)
    # if experimentRange == "00to90" or "90to180":
    #     if type == "linearPrior" or type == "prior" or type =="curvedPrior":
    #         return (1-m)*foldLow + m*truncUp # The lowed values get folded while upper ones are truncated
    #     if type == "inverseLinearPrior" or type == "inversePrior" or type =="inverseCurvedPrior":
    #         return m*foldUp + (1-m)*truncLow # The lowed values get truncated while upper ones are folded
    # if experimentRange == "00to180" or experimentRange == "noBoundaryEffects":
        # We assume that they represent the information here totally and the bounds do not mean truncation but rather,
        # they jusst shift the boundary values to include 5 standard deviations from the noise, whatever the noise is
        # return ss.norm.pdf(grid, m+5*sigma_rep*(0.5-m), sigma_rep)
    return truncBoth



# Initially used value function with dded line to generate all kinds of mappings
# that are increasing, decreasing and so on
def value_function_ori(x, type, line_frac = 0):
    x = np.array(x)
    line = abs(stim_ori_grid/np.pi/2.*factor_val - max_val)*line_frac
    if experimentRange == "00to180":

        if type == "cdf_prior":
            value_function = integrate.cumtrapz(prior_ori(x), stim_ori_grid, initial=0.0)*factor_val
            
        if type == "prior":
            value_function = np.zeros_like(x)
            value_function[x <= np.pi/2] = (max_val - ((max_val-min_val)/4)*(np.sin((x)[x <= np.pi/2])))
            value_function[(x > np.pi/2) & (x <= 3*np.pi/2)] = (max_val - (max_val-min_val)/2) - ((max_val-min_val)/4)*( - np.sin((x)[(x > np.pi/2) & (x <= 3*np.pi/2)]))
            value_function[x > 3*np.pi/2] = min_val - ((max_val-min_val)/4)*(np.sin((x)[x > 3*np.pi/2]))
            
        if type == "linearPrior":
            value_function = max_val -abs((max_val-min_val)*x/2/np.pi)

        if type == "curvedPrior":
            value_function = np.zeros_like(x)
            value_function[x <= np.pi] = (max_val)-((max_val-min_val)/4)*(1-np.cos(x[x <= np.pi]))
            value_function[(x > np.pi) & (x <= np.pi*2)] = (max_val+min_val)/2 -((max_val-min_val)/4)*(np.cos(x[(x > np.pi) & (x <= np.pi*2)])+1)

        if type == "inversePrior":
            value_function = np.zeros_like(x)
            value_function[x <= np.pi/2] = min_val + ((max_val-min_val)/4)*(np.sin(x[x <= np.pi/2]))
            value_function[(x > np.pi/2) & (x <= 3*np.pi/2)] = min_val + ((max_val-min_val)/4)*(2 - np.sin(x[(x > np.pi/2) & (x <= 3*np.pi/2)]))
            value_function[x > 3*np.pi/2] = ((max_val-min_val)/4)*(np.sin(x[x > 3*np.pi/2])) + max_val

        if type == "inverseLinearPrior":
            value_function = min_val + abs((max_val-min_val)*x/2/np.pi)

        if type == "inverseCurvedPrior":
            value_function = np.zeros_like(x)
            value_function[x <= np.pi] = min_val + ((max_val-min_val)/4)*(1-np.cos(x[x <= np.pi]))
            value_function[(x > np.pi) & (x <= np.pi*2)] = (max_val+min_val)/2 +((max_val-min_val)/4)*(np.cos(x[(x > np.pi) & (x <= np.pi*2)])+1)

    if experimentRange == "45to225":
        if type == "prior":
            value_function = np.zeros_like(x)
            value_function[x <= np.pi+displace] = (max_val)-((max_val-min_val)/4)*(1-np.cos((x-displace)[x <= np.pi+displace]))
            value_function[(x > np.pi+displace) & (x <= np.pi*2+displace)] = (max_val+min_val)/2 -((max_val-min_val)/4)*(np.cos((x-displace)[(x > np.pi+displace) & (x <= np.pi*2+displace)])+1)

        if type == "linearPrior":
            value_function = max_val -abs((max_val-min_val)*(x-displace)/2/np.pi)

        if type == "curvedPrior":
            value_function = np.zeros_like(x)
            value_function[x <= np.pi/2+displace] = max_val - ((max_val-min_val)/4)*(np.sin((x-displace)[x <= np.pi/2+displace]))
            value_function[(x > np.pi/2+displace) & (x <= 3*np.pi/2+displace)] = (max_val - (max_val-min_val)/2) - ((max_val-min_val)/4)*( - np.sin((x-displace)[(x > np.pi/2+displace) & (x <= 3*np.pi/2+displace)]))
            value_function[x > 3*np.pi/2+displace] = min_val - ((max_val-min_val)/4)*(np.sin((x-displace)[x > 3*np.pi/2+displace]))

        if type == "inversePrior":
            value_function = np.zeros_like(x)
            value_function[x <= np.pi+displace] = min_val + ((max_val-min_val)/4)*(1-np.cos((x-displace)[x <= np.pi+displace]))
            value_function[(x > np.pi+displace) & (x <= np.pi*2+displace)] = (max_val+min_val)/2 +((max_val-min_val)/4)*(np.cos((x-displace)[(x > np.pi+displace) & (x <= np.pi*2+displace)])+1)


        if type == "inverseLinearPrior":
            value_function = min_val + abs((max_val-min_val)*(x-displace)/2/np.pi)

        if type == "inverseCurvedPrior":
            value_function = np.zeros_like(x)
            value_function[x <= np.pi/2+displace] = min_val + ((max_val-min_val)/4)*(np.sin((x-displace)[x <= np.pi/2+displace]))
            value_function[(x > np.pi/2+displace) & (x <= 3*np.pi/2+displace)] = min_val + ((max_val-min_val)/4)*(2 - np.sin((x-displace)[(x > np.pi/2+displace) & (x <= 3*np.pi/2+displace)]))
            value_function[x > 3*np.pi/2+displace] = ((max_val-min_val)/4)*(np.sin((x-displace)[x > 3*np.pi/2+displace])) + max_val

    order = np.argsort(value_function)[::-1]
    value_function = value_function*(1-line_frac)+line[order]

    return value_function


# A general numerical method is used here to find new distributions of functions of distributions we know.
# Takes in the grid used in original distribution, and the distribution of the original distribution and then
# finds the distribution of the functional value distribution.
# The parameter "monotonic" is true when the value function with respect to input orientations is 
# a monotonic function. If not, we would have to use either histograms or kde. However, if it is, then
# a simple transformation is enough and that is what we do. wE GENERALIZE THIS HERE IN THE TOOLS script
def ori_to_val_dist(grid, p, type, line_frac, bins=500, monotonic=True, interpolation_kind='linear'):
    x_stim = np.array(grid)
    p_stim = p

    assert (x_stim.ndim == 1), "x_stim should have only one dimension (same grid for all p_stims)"
    if p_stim.ndim == 1:
        p_stim = p_stim[np.newaxis,:]


    if monotonic:
        x_value = value_function_ori(x_stim, type, line_frac)
        bin_centers = x_value
        grad_val = np.gradient(x_value, x_stim)#grad_value_ori(x_stim, type)
        grad_ori = 1/grad_val
        ps = p_stim*abs(grad_ori)

    else:
        # For every bin in x_stim, calculate the probability mass within that bin
        dx = x_stim[..., 1:] - x_stim[..., :-1]
        p_mass = ((p_stim[..., 1:] + p_stim[..., :-1]) / 2) * dx

        # Get the center of every bin
        x_value = value_function_ori(x_stim[:-1] + dx / 2., type, line_frac)
        ps = []
        for ix in range(len(p_stim)):
            h, edges = np.histogram(x_value, bins=bins, weights=p_mass[ix], density=True)
            ps.append(h)

        ps = np.array(ps)
        bin_centers = (edges[1:] + edges[:-1]) / 2

        f = interpolate.interp1d(bin_centers, ps, axis=1,
                                 kind=interpolation_kind, fill_value='extrapolate')

        ps = f(bin_centers)
        
        ps /= np.trapz(ps, bin_centers, axis=1)[:, np.newaxis]
    
    ps = ps[:, np.argsort(bin_centers)]
    bin_centers = np.sort(bin_centers)

    # ps /= np.trapz(ps, bin_centers, axis=1)[:, np.newaxis]

    return bin_centers, ps


# Steeper prior for enhanced repulsion and attraction effects
def prior_ori(x):  ## This one is for modelling the steeper prior
    if experimentRange == "00to180" or experimentRange == "noBoundaryEffects":
        return (40 - np.abs(38*np.sin(x))) / (-152 + 80*np.pi)
    if experimentRange == "00to90" or experimentRange == "90to180":
        return (2 - np.abs(np.sin(x))) / (np.pi - 1) / 2.0
    if experimentRange == "00to45" or experimentRange == "45to90" or experimentRange == "90to135" or experimentRange == "135to180":
        return (2 - np.abs(np.sin(x))) / (np.pi - 1)

# analytical solutions for gradient of the original value function with respect to the orientations
def grad_value_ori(x, type, line_frac = 0.0):
    x = np.array(x)
    if experimentRange == "00to180":

        if type == "cdf_prior":
            grad_val = prior_ori(x)*factor_val

        if type == "increase_cdf_prior":
            grad_val = prior_ori(x)*factor_val/2./np.sqrt(integrate.cumtrapz(prior_ori(x), stim_ori_grid, initial=0.00001))

        if type == "prior":
            grad_val = np.zeros_like(x)
            grad_val[x <= np.pi/2] = ((max_val-min_val)/4)*(np.cos((x)[x <= np.pi/2]))
            grad_val[(x > np.pi/2) & (x <= 3*np.pi/2)] = ((max_val-min_val)/4)*( - np.cos((x)[(x > np.pi/2) & (x <= 3*np.pi/2)]))
            grad_val[x > 3*np.pi/2] = ((max_val-min_val)/4)*(np.cos((x)[x > 3*np.pi/2]))

        if type == "linearPrior":
            grad_val = -abs((max_val-min_val)*1/2/np.pi)

        if type == "curvedPrior":
            grad_val = np.zeros_like(x)
            grad_val[x <= np.pi] = ((max_val-min_val)/4)*(1+np.sin(x[x <= np.pi]))
            grad_val[(x > np.pi) & (x <= np.pi*2)] = -((max_val-min_val)/4)*(-np.sin(x[(x > np.pi) & (x <= np.pi*2)]))

        if type == "inversePrior":
            grad_val = np.zeros_like(x)
            grad_val[x <= np.pi/2] = ((max_val-min_val)/4)*(np.cos(x[x <= np.pi/2]))
            grad_val[(x > np.pi/2) & (x <= 3*np.pi/2)] = ((max_val-min_val)/4)*(2 - np.cos(x[(x > np.pi/2) & (x <= 3*np.pi/2)]))
            grad_val[x > 3*np.pi/2] = ((max_val-min_val)/4)*(np.cos(x[x > 3*np.pi/2]))

        if type == "inverseLinearPrior":
            grad_val = abs((max_val-min_val)*1/2/np.pi)

        if type == "inverseCurvedPrior":
            grad_val = np.zeros_like(x)
            grad_val[x <= np.pi] = ((max_val-min_val)/4)*(1+np.sin(x[x <= np.pi]))
            grad_val[(x > np.pi) & (x <= np.pi*2)] = ((max_val-min_val)/4)*(-np.sin(x[(x > np.pi) & (x <= np.pi*2)]))

    if experimentRange == "45to225":

        if type == "cdf_prior":
            grad_val = prior_ori(x-displace)*factor_val

        if type == "prior":
            grad_val = np.zeros_like(x)
            grad_val[x <= np.pi+displace] = ((max_val-min_val)/4)*(1+np.sin((x-displace)[x <= np.pi+displace]))
            grad_val[(x > np.pi+displace) & (x <= np.pi*2+displace)] = -((max_val-min_val)/4)*(-np.sin((x-displace)[(x > np.pi+displace) & (x <= np.pi*2+displace)])+1)

        if type == "linearPrior":
            grad_val = -abs((max_val-min_val)*(1)/2/np.pi)

        if type == "curvedPrior":
            grad_val = np.zeros_like(x)
            grad_val[x <= np.pi/2+displace] = ((max_val-min_val)/4)*(np.cos((x-displace)[x <= np.pi/2+displace]))
            grad_val[(x > np.pi/2+displace) & (x <= 3*np.pi/2+displace)] = - ((max_val-min_val)/4)*( - np.cos((x-displace)[(x > np.pi/2+displace) & (x <= 3*np.pi/2+displace)]))
            grad_val[x > 3*np.pi/2+displace] = - ((max_val-min_val)/4)*(np.cos((x-displace)[x > 3*np.pi/2+displace]))

        if type == "inversePrior":
            grad_val = np.zeros_like(x)
            grad_val[x <= np.pi+displace] = ((max_val-min_val)/4)*(1+np.sin((x-displace)[x <= np.pi+displace]))
            grad_val[(x > np.pi+displace) & (x <= np.pi*2+displace)] = ((max_val-min_val)/4)*(-np.sin((x-displace)[(x > np.pi+displace) & (x <= np.pi*2+displace)])+1)


        if type == "inverseLinearPrior":
            grad_val = abs((max_val-min_val)*(1)/2/np.pi)

        if type == "inverseCurvedPrior":
            grad_val = np.zeros_like(x)
            grad_val[x <= np.pi/2+displace] = ((max_val-min_val)/4)*(-np.cos((x-displace)[x <= np.pi/2+displace]))
            grad_val[(x > np.pi/2+displace) & (x <= 3*np.pi/2+displace)] = ((max_val-min_val)/4)*(2 - np.cos((x-displace)[(x > np.pi/2+displace) & (x <= 3*np.pi/2+displace)]))
            grad_val[x > 3*np.pi/2+displace] = ((max_val-min_val)/4)*(np.cos((x-displace)[x > 3*np.pi/2+displace]))

    grad_val = grad_val + line_frac/np.pi/2.*factor_val

    return grad_val
